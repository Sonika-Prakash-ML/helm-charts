{{- $result := mulf (mulf .Values.worker.podmem 0.8) 1 }}
{{- $resultInt := int $result }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "sf-presto.fullname" . }}-worker
  labels:
    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    app.kubernetes.io/name: {{ .Chart.Name }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/component: resource-manager
    app.kubernetes.io/version: {{ .Values.image.tag | default .Chart.AppVersion | quote }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
data:
  azure-site.xml: |+
    <configuration>
      <property>
        <name>fs.azure.account.keyprovider.account.blob.core.windows.net</name>
        <value>org.apache.hadoop.fs.azure.SimpleKeyProvider</value>
      </property>
      <property>
        <name>fs.azure.account.key.{{ .Values.azure.account }}.blob.core.windows.net</name>
        <value>{{ .Values.azure.accessKey }}</value>
      </property>
      <property>
        <name>fs.AbstractFileSystem.wasb.impl</name>
        <value>org.apache.hadoop.fs.azure.Wasb</value>
      </property>
      <property>
        <name>fs.AbstractFileSystem.wasbs.impl</name>
        <value>org.apache.hadoop.fs.azure.Wasbs</value>
      </property>
      <property>
        <name>fs.azure.enable.append.support</name>
        <value>true</value>
      </property>
    </configuration>
  node.properties: |-
    node.environment=production
    node.data-dir=/var/presto/data
  jvm.config: |-
    -server
    -Xmx{{ $resultInt }}M
    -XX:+UseG1GC
    -XX:G1HeapRegionSize=32M
    -XX:+UseGCOverheadLimit
    -XX:+ExplicitGCInvokesConcurrent
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:+ExitOnOutOfMemoryError
    -Djdk.attach.allowAttachSelf=true
    -Duser.timezone=UTC
  config.properties: |-
    coordinator=false
    http-server.http.port={{ .Values.service.port }}
    discovery.uri=http://{{ .Release.Name }}-discovery:{{ .Values.service.port }}
    http-server.log.max-history=2
    resource-manager-enabled=true
    experimental.query-limit-spill-enabled=true

    # Refer https://aws.amazon.com/blogs/big-data/top-9-performance-tuning-tips-for-prestodb-on-amazon-emr/ & https://techjogging.com/memory-setup-prestodb-cluster.html
    query.max-queued-queries=5000
    query.max-history=1000
    query.max-concurrent-queries=10
    query.execution-policy=phased
    task.concurrency=4
    task.max-worker-threads=16
    task.http-response-threads=100

    shutdown.grace-period={{ .Values.env.Grace_Period_Seconds }}s

    # Cluster level config depends on worker size
    query.max-memory-per-node={{ mulf .Values.worker.podmem 0.32 }}MB
    query.max-total-memory-per-node={{ mulf .Values.worker.podmem 0.384 }}MB
    query.max-memory={{ mulf .Values.worker.podmem 0.32 .Values.autoscaling.worker.maxReplicas }}MB
    query.max-total-memory={{ mulf .Values.worker.podmem 0.384 .Values.autoscaling.worker.maxReplicas }}MB
    memory.heap-headroom-per-node={{ mulf .Values.worker.podmem 0.16 }}MB
  log.properties: |-
    com.facebook.presto=DEBUG
